# Speech Emotion Recognition

This project involves developing a deep learning model to accurately classify human emotions from speech using the MLPClassifier in Sklearn. The model was trained on the RAVDESS and SAVEE datasets, which together contain over 7,000 audio files representing various emotional states. The objective is to enhance customer sentiment analysis by detecting emotions through speech, which can be applied in various fields such as customer service, mental health, and human-computer interaction.

## Key Features:
- **Datasets**: RAVDESS and SAVEE, consisting of diverse emotional speech recordings.
- **Technologies Used**: Python, Sklearn, Librosa, and other audio processing libraries.
- **Model**: MLPClassifier, designed to process raw audio data and output classified emotions.
- **Applications**: Can be integrated into systems for real-time emotion detection in voice assistants, call centers, and other AI-driven applications.

This repository contains the codebase, datasets (links provided), and instructions for training and testing the model. Contributions and suggestions are welcome!
